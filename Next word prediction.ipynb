{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "166c6ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31fc77fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../../datasets/nextword.txt\",delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a421bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=['nextword']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63147863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nextword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This eBook is for the use of anyone anywhere a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>almost no restrictions whatsoever.  You may co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>re-use it under the terms of the Project Guten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>with this eBook or online at www.gutenberg.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Title: The Adventures of Sherlock Holmes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9627</th>\n",
       "      <td>facility: www.gutenberg.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9628</th>\n",
       "      <td>This Web site includes information about Proje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9629</th>\n",
       "      <td>including how to make donations to the Project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9630</th>\n",
       "      <td>Archive Foundation, how to help produce our ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9631</th>\n",
       "      <td>subscribe to our email newsletter to hear abou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9632 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               nextword\n",
       "0     This eBook is for the use of anyone anywhere a...\n",
       "1     almost no restrictions whatsoever.  You may co...\n",
       "2     re-use it under the terms of the Project Guten...\n",
       "3        with this eBook or online at www.gutenberg.net\n",
       "4              Title: The Adventures of Sherlock Holmes\n",
       "...                                                 ...\n",
       "9627                        facility: www.gutenberg.org\n",
       "9628  This Web site includes information about Proje...\n",
       "9629  including how to make donations to the Project...\n",
       "9630  Archive Foundation, how to help produce our ne...\n",
       "9631  subscribe to our email newsletter to hear abou...\n",
       "\n",
       "[9632 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7cb8ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean(r0):\n",
    "    return re.sub('<.*?>',' ',r0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "682d5160",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nextword'] = df['nextword'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9282603a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44b7dde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df['nextword'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3447cbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words=len(tokenizer.index_word)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec2c50c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8930"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74e1d12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in df['nextword']:\n",
    "    tokens = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(tokens)):\n",
    "        n_gram_sequence = tokens[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "438e6ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "max_sequence_length = max(len(seq) for seq in input_sequences)\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51f28c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = input_sequences[:, :-1]\n",
    "y = input_sequences[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a72b48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y = to_categorical(y, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e05a1f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 128, input_length=max_sequence_length - 1))\n",
    "model.add(LSTM(50, return_sequences=True))\n",
    "model.add(LSTM(50, return_sequences=True))\n",
    "model.add(LSTM(50, return_sequences=True))\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85b5b405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1527/1527 [==============================] - 104s 62ms/step - loss: 6.5430 - accuracy: 0.0543\n",
      "Epoch 2/100\n",
      "1527/1527 [==============================] - 96s 63ms/step - loss: 6.4321 - accuracy: 0.0544\n",
      "Epoch 3/100\n",
      "1527/1527 [==============================] - 97s 64ms/step - loss: 6.4319 - accuracy: 0.0544\n",
      "Epoch 4/100\n",
      "1527/1527 [==============================] - 96s 63ms/step - loss: 6.4315 - accuracy: 0.0544\n",
      "Epoch 5/100\n",
      "1527/1527 [==============================] - 95s 62ms/step - loss: 6.4305 - accuracy: 0.0544\n",
      "Epoch 6/100\n",
      "1527/1527 [==============================] - 98s 64ms/step - loss: 6.4313 - accuracy: 0.0544\n",
      "Epoch 7/100\n",
      "1527/1527 [==============================] - 97s 63ms/step - loss: 6.4318 - accuracy: 0.0544\n",
      "Epoch 8/100\n",
      "1527/1527 [==============================] - 95s 62ms/step - loss: 6.4313 - accuracy: 0.0544\n",
      "Epoch 9/100\n",
      "1527/1527 [==============================] - 95s 62ms/step - loss: 6.4294 - accuracy: 0.0544\n",
      "Epoch 10/100\n",
      "1527/1527 [==============================] - 95s 62ms/step - loss: 6.4310 - accuracy: 0.0544\n",
      "Epoch 11/100\n",
      "1527/1527 [==============================] - 97s 64ms/step - loss: 6.4312 - accuracy: 0.0544\n",
      "Epoch 12/100\n",
      "1527/1527 [==============================] - 96s 63ms/step - loss: 6.4309 - accuracy: 0.0544\n",
      "Epoch 13/100\n",
      "1527/1527 [==============================] - 97s 63ms/step - loss: 6.4308 - accuracy: 0.0544\n",
      "Epoch 14/100\n",
      "1527/1527 [==============================] - 93s 61ms/step - loss: 6.4312 - accuracy: 0.0544\n",
      "Epoch 15/100\n",
      "1527/1527 [==============================] - 92s 60ms/step - loss: 6.4308 - accuracy: 0.0544\n",
      "Epoch 16/100\n",
      "1527/1527 [==============================] - 94s 61ms/step - loss: 6.4309 - accuracy: 0.0544\n",
      "Epoch 17/100\n",
      "1527/1527 [==============================] - 93s 61ms/step - loss: 6.4289 - accuracy: 0.0544\n",
      "Epoch 18/100\n",
      "1527/1527 [==============================] - 92s 60ms/step - loss: 6.4289 - accuracy: 0.0544\n",
      "Epoch 19/100\n",
      "1527/1527 [==============================] - 92s 60ms/step - loss: 6.4288 - accuracy: 0.0543\n",
      "Epoch 20/100\n",
      "1527/1527 [==============================] - 92s 60ms/step - loss: 6.3109 - accuracy: 0.0562\n",
      "Epoch 21/100\n",
      "1527/1527 [==============================] - 92s 60ms/step - loss: 6.1726 - accuracy: 0.0695\n",
      "Epoch 22/100\n",
      "1527/1527 [==============================] - 93s 61ms/step - loss: 6.0815 - accuracy: 0.0779\n",
      "Epoch 23/100\n",
      "1527/1527 [==============================] - 92s 61ms/step - loss: 6.0208 - accuracy: 0.0828\n",
      "Epoch 24/100\n",
      "1527/1527 [==============================] - 93s 61ms/step - loss: 5.9678 - accuracy: 0.0875\n",
      "Epoch 25/100\n",
      "1527/1527 [==============================] - 92s 60ms/step - loss: 5.8884 - accuracy: 0.0947\n",
      "Epoch 26/100\n",
      "1527/1527 [==============================] - 93s 61ms/step - loss: 5.8134 - accuracy: 0.1063\n",
      "Epoch 27/100\n",
      "1527/1527 [==============================] - 92s 61ms/step - loss: 5.7467 - accuracy: 0.1146\n",
      "Epoch 28/100\n",
      "1527/1527 [==============================] - 92s 60ms/step - loss: 5.6906 - accuracy: 0.1206\n",
      "Epoch 29/100\n",
      "1527/1527 [==============================] - 92s 60ms/step - loss: 5.6421 - accuracy: 0.1252\n",
      "Epoch 30/100\n",
      "1527/1527 [==============================] - 92s 60ms/step - loss: 5.6021 - accuracy: 0.1297\n",
      "Epoch 31/100\n",
      "1527/1527 [==============================] - 93s 61ms/step - loss: 5.5636 - accuracy: 0.1343\n",
      "Epoch 32/100\n",
      "1527/1527 [==============================] - 97s 63ms/step - loss: 5.5255 - accuracy: 0.1394\n",
      "Epoch 33/100\n",
      "1527/1527 [==============================] - 96s 63ms/step - loss: 5.4928 - accuracy: 0.1439\n",
      "Epoch 34/100\n",
      "1527/1527 [==============================] - 94s 62ms/step - loss: 5.4629 - accuracy: 0.1475\n",
      "Epoch 35/100\n",
      "1527/1527 [==============================] - 91s 60ms/step - loss: 5.4327 - accuracy: 0.1517\n",
      "Epoch 36/100\n",
      "1527/1527 [==============================] - 92s 60ms/step - loss: 5.4024 - accuracy: 0.1556\n",
      "Epoch 37/100\n",
      "1527/1527 [==============================] - 92s 60ms/step - loss: 5.3727 - accuracy: 0.1589\n",
      "Epoch 38/100\n",
      "1527/1527 [==============================] - 93s 61ms/step - loss: 5.3454 - accuracy: 0.1620\n",
      "Epoch 39/100\n",
      "1527/1527 [==============================] - 92s 60ms/step - loss: 5.3167 - accuracy: 0.1671\n",
      "Epoch 40/100\n",
      "1527/1527 [==============================] - 93s 61ms/step - loss: 5.2831 - accuracy: 0.1714\n",
      "Epoch 41/100\n",
      "1527/1527 [==============================] - 92s 60ms/step - loss: 5.2548 - accuracy: 0.1740\n",
      "Epoch 42/100\n",
      "1527/1527 [==============================] - 93s 61ms/step - loss: 5.2245 - accuracy: 0.1780\n",
      "Epoch 43/100\n",
      "1527/1527 [==============================] - 92s 60ms/step - loss: 5.1948 - accuracy: 0.1823\n",
      "Epoch 44/100\n",
      "1527/1527 [==============================] - 92s 60ms/step - loss: 5.1663 - accuracy: 0.1866\n",
      "Epoch 45/100\n",
      "1527/1527 [==============================] - 92s 60ms/step - loss: 5.1388 - accuracy: 0.1899\n",
      "Epoch 46/100\n",
      "1527/1527 [==============================] - 93s 61ms/step - loss: 5.1097 - accuracy: 0.1944\n",
      "Epoch 47/100\n",
      "1527/1527 [==============================] - 92s 60ms/step - loss: 5.0830 - accuracy: 0.1972\n",
      "Epoch 48/100\n",
      "1527/1527 [==============================] - 92s 60ms/step - loss: 5.0564 - accuracy: 0.2010\n",
      "Epoch 49/100\n",
      "1527/1527 [==============================] - 92s 60ms/step - loss: 5.0289 - accuracy: 0.2055\n",
      "Epoch 50/100\n",
      "1527/1527 [==============================] - 92s 60ms/step - loss: 5.0035 - accuracy: 0.2086\n",
      "Epoch 51/100\n",
      "1527/1527 [==============================] - 92s 61ms/step - loss: 4.9734 - accuracy: 0.2130\n",
      "Epoch 52/100\n",
      "1527/1527 [==============================] - 4657s 3s/step - loss: 4.9494 - accuracy: 0.2156\n",
      "Epoch 53/100\n",
      "1527/1527 [==============================] - 99s 65ms/step - loss: 4.9216 - accuracy: 0.2192\n",
      "Epoch 54/100\n",
      "1527/1527 [==============================] - 96s 63ms/step - loss: 4.8963 - accuracy: 0.2234\n",
      "Epoch 55/100\n",
      "1527/1527 [==============================] - 100s 65ms/step - loss: 4.8708 - accuracy: 0.2263\n",
      "Epoch 56/100\n",
      "1527/1527 [==============================] - 96s 63ms/step - loss: 4.8458 - accuracy: 0.2309\n",
      "Epoch 57/100\n",
      "1527/1527 [==============================] - 96s 63ms/step - loss: 4.8206 - accuracy: 0.2346\n",
      "Epoch 58/100\n",
      "1527/1527 [==============================] - 97s 63ms/step - loss: 4.7953 - accuracy: 0.2376\n",
      "Epoch 59/100\n",
      "1527/1527 [==============================] - 96s 63ms/step - loss: 4.7722 - accuracy: 0.2409\n",
      "Epoch 60/100\n",
      "1527/1527 [==============================] - 96s 63ms/step - loss: 4.7499 - accuracy: 0.2450\n",
      "Epoch 61/100\n",
      "1527/1527 [==============================] - 97s 64ms/step - loss: 4.7271 - accuracy: 0.2483\n",
      "Epoch 62/100\n",
      "1527/1527 [==============================] - 97s 63ms/step - loss: 4.7062 - accuracy: 0.2518\n",
      "Epoch 63/100\n",
      "1527/1527 [==============================] - 97s 64ms/step - loss: 4.6842 - accuracy: 0.2548\n",
      "Epoch 64/100\n",
      "1527/1527 [==============================] - 94s 61ms/step - loss: 4.6613 - accuracy: 0.2572\n",
      "Epoch 65/100\n",
      "1527/1527 [==============================] - 93s 61ms/step - loss: 4.6423 - accuracy: 0.2601\n",
      "Epoch 66/100\n",
      "1527/1527 [==============================] - 92s 60ms/step - loss: 4.6209 - accuracy: 0.2634\n",
      "Epoch 67/100\n",
      "1527/1527 [==============================] - 93s 61ms/step - loss: 4.6000 - accuracy: 0.2660\n",
      "Epoch 68/100\n",
      "1527/1527 [==============================] - 91s 60ms/step - loss: 4.5771 - accuracy: 0.2697\n",
      "Epoch 69/100\n",
      "1527/1527 [==============================] - 92s 60ms/step - loss: 4.5570 - accuracy: 0.2706\n",
      "Epoch 70/100\n",
      "1527/1527 [==============================] - 94s 61ms/step - loss: 4.5411 - accuracy: 0.2738\n",
      "Epoch 71/100\n",
      "1527/1527 [==============================] - 92s 60ms/step - loss: 4.5184 - accuracy: 0.2760\n",
      "Epoch 72/100\n",
      "1527/1527 [==============================] - 92s 60ms/step - loss: 4.5033 - accuracy: 0.2799\n",
      "Epoch 73/100\n",
      "1527/1527 [==============================] - 94s 61ms/step - loss: 4.4883 - accuracy: 0.2817\n",
      "Epoch 74/100\n",
      "1527/1527 [==============================] - 94s 61ms/step - loss: 4.4703 - accuracy: 0.2845\n",
      "Epoch 75/100\n",
      "1527/1527 [==============================] - 93s 61ms/step - loss: 4.4581 - accuracy: 0.2860\n",
      "Epoch 76/100\n",
      "1527/1527 [==============================] - 91s 60ms/step - loss: 4.4409 - accuracy: 0.2887\n",
      "Epoch 77/100\n",
      "1527/1527 [==============================] - 100s 66ms/step - loss: 4.4286 - accuracy: 0.2902\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 95s 63ms/step - loss: 4.4141 - accuracy: 0.2936\n",
      "Epoch 79/100\n",
      "1527/1527 [==============================] - 98s 64ms/step - loss: 4.4008 - accuracy: 0.2943\n",
      "Epoch 80/100\n",
      "1527/1527 [==============================] - 100s 65ms/step - loss: 4.3901 - accuracy: 0.2968\n",
      "Epoch 81/100\n",
      "1527/1527 [==============================] - 98s 64ms/step - loss: 4.3751 - accuracy: 0.2993\n",
      "Epoch 82/100\n",
      "1527/1527 [==============================] - 98s 64ms/step - loss: 4.3635 - accuracy: 0.3002\n",
      "Epoch 83/100\n",
      "1527/1527 [==============================] - 96s 63ms/step - loss: 4.3512 - accuracy: 0.3031\n",
      "Epoch 84/100\n",
      "1527/1527 [==============================] - 96s 63ms/step - loss: 4.3394 - accuracy: 0.3046\n",
      "Epoch 85/100\n",
      "1527/1527 [==============================] - 96s 63ms/step - loss: 4.3264 - accuracy: 0.3063\n",
      "Epoch 86/100\n",
      "1527/1527 [==============================] - 97s 64ms/step - loss: 4.3149 - accuracy: 0.3080\n",
      "Epoch 87/100\n",
      "1527/1527 [==============================] - 97s 64ms/step - loss: 4.3069 - accuracy: 0.3091\n",
      "Epoch 88/100\n",
      "1527/1527 [==============================] - 98s 64ms/step - loss: 4.2959 - accuracy: 0.3114\n",
      "Epoch 89/100\n",
      "1527/1527 [==============================] - 96s 63ms/step - loss: 4.2828 - accuracy: 0.3134\n",
      "Epoch 90/100\n",
      "1527/1527 [==============================] - 98s 64ms/step - loss: 4.2704 - accuracy: 0.3146\n",
      "Epoch 91/100\n",
      "1527/1527 [==============================] - 99s 65ms/step - loss: 4.2559 - accuracy: 0.3168\n",
      "Epoch 92/100\n",
      "1527/1527 [==============================] - 96s 63ms/step - loss: 4.2485 - accuracy: 0.3177\n",
      "Epoch 93/100\n",
      "1527/1527 [==============================] - 93s 61ms/step - loss: 4.2349 - accuracy: 0.3190\n",
      "Epoch 94/100\n",
      "1527/1527 [==============================] - 92s 60ms/step - loss: 4.2288 - accuracy: 0.3209\n",
      "Epoch 95/100\n",
      "1527/1527 [==============================] - 92s 60ms/step - loss: 4.2167 - accuracy: 0.3229\n",
      "Epoch 96/100\n",
      "1527/1527 [==============================] - 92s 60ms/step - loss: 4.2074 - accuracy: 0.3234\n",
      "Epoch 97/100\n",
      "1527/1527 [==============================] - 92s 61ms/step - loss: 4.1997 - accuracy: 0.3252\n",
      "Epoch 98/100\n",
      "1527/1527 [==============================] - 92s 60ms/step - loss: 4.1895 - accuracy: 0.3269\n",
      "Epoch 99/100\n",
      "1527/1527 [==============================] - 93s 61ms/step - loss: 4.1789 - accuracy: 0.3277\n",
      "Epoch 100/100\n",
      "1527/1527 [==============================] - 94s 62ms/step - loss: 4.1711 - accuracy: 0.3293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29aa6442d70>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=100,batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96ae7a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\dsml_25_tf\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('nextword.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec3808a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f652c4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('nextword.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c148eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = ['it includes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e16a466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokenized = tokenizer.texts_to_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54630385",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_padded_reviews = pad_sequences(test_tokenized,19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65b93726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7.5060188e-06, 2.0792428e-03, 4.9238544e-02, ..., 7.7261084e-06,\n",
       "        7.4351165e-06, 7.4710533e-06]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_padded_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53b4fab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsml_25_tf]",
   "language": "python",
   "name": "conda-env-dsml_25_tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
